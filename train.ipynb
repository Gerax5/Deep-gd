{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7b3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from gd_env import GeometryEnv\n",
    "from model import DQN\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed88a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(episodes=1000, checkpoint_path=None):\n",
    "    env = GeometryEnv()\n",
    "\n",
    "    sample_state = env.reset()\n",
    "    state_dim = len(sample_state)\n",
    "    n_actions = 2\n",
    "\n",
    "    print(f\"Estado inicial: shape={sample_state.shape}, dim={state_dim}\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Usando dispositivo:\", device)\n",
    "\n",
    "    policy_net = DQN(state_dim, n_actions).to(device)\n",
    "    target_net = DQN(state_dim, n_actions).to(device)\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=1e-3)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "\n",
    "    memory = deque(maxlen=50000)\n",
    "    batch_size = 64\n",
    "    gamma = 0.99\n",
    "    eps = 1.0\n",
    "    eps_min = 0.05\n",
    "    eps_decay = 0.995\n",
    "    update_target_every = 100\n",
    "    start_ep = 0 \n",
    "\n",
    "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        print(f\"Cargando checkpoint desde: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "        if \"policy_state\" in checkpoint:\n",
    "            policy_net.load_state_dict(checkpoint[\"policy_state\"])\n",
    "            target_net.load_state_dict(checkpoint[\"target_state\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "            eps = checkpoint.get(\"epsilon\", 1.0)\n",
    "            start_ep = checkpoint.get(\"episode\", 0)\n",
    "        else:\n",
    "            policy_net.load_state_dict(checkpoint)\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        print(f\"Checkpoint cargado correctamente (episodio {start_ep})\")\n",
    "\n",
    "    else:\n",
    "        print(\"No se encontr√≥ checkpoint, entrenamiento desde cero.\")\n",
    "\n",
    "    target_net.eval()\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    # ===============================\n",
    "    # ENTRENAMIENTO PRINCIPAL\n",
    "    # ===============================\n",
    "    for ep in range(start_ep, episodes):\n",
    "        s = env.reset().astype(np.float32)\n",
    "        total_r = 0.0\n",
    "        done = False\n",
    "\n",
    "        for t in range(2000):\n",
    "            if np.any(np.isnan(s)):\n",
    "                print(f\"Estado NaN en ep {ep}, t={t}. Reiniciando entorno.\")\n",
    "                s = env.reset().astype(np.float32)\n",
    "                continue\n",
    "\n",
    "            # Acci√≥n epsilon-greedy\n",
    "            if random.random() < eps:\n",
    "                a = random.randrange(n_actions)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    qvals = policy_net(torch.tensor(s, dtype=torch.float32, device=device).unsqueeze(0))\n",
    "                    a = int(torch.argmax(qvals).item())\n",
    "\n",
    "            s2, r, done, _ = env.step(a)\n",
    "            s2 = np.array(s2, dtype=np.float32)\n",
    "            memory.append((s, a, r, s2, done))\n",
    "            s = s2\n",
    "            total_r += r\n",
    "\n",
    "            # Entrenamiento\n",
    "            if len(memory) < batch_size:\n",
    "                continue\n",
    "\n",
    "            batch = random.sample(memory, batch_size)\n",
    "            s_b = torch.tensor(np.array([x[0] for x in batch]), dtype=torch.float32, device=device)\n",
    "            a_b = torch.tensor([x[1] for x in batch], dtype=torch.int64, device=device).unsqueeze(1)\n",
    "            r_b = torch.tensor([x[2] for x in batch],dtype=torch.float32, device=device ), \n",
    "            r_b = torch.tensor([x[2] for x in batch], dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            s2_b = torch.tensor(np.array([x[3] for x in batch]), dtype=torch.float32, device=device)\n",
    "            d_b = torch.tensor([x[4] for x in batch], dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "            if s_b.shape[1] != state_dim:\n",
    "                print(f\"Shape error: s_b {s_b.shape}, esperado (*, {state_dim})\")\n",
    "                continue\n",
    "\n",
    "            q_vals = policy_net(s_b).gather(1, a_b)\n",
    "            with torch.no_grad():\n",
    "                next_q = target_net(s2_b).max(1, keepdim=True)[0]\n",
    "            target = r_b + gamma * next_q * (1 - d_b)\n",
    "\n",
    "            loss = criterion(q_vals, target)\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"Loss NaN en ep {ep}, paso {t}\")\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(policy_net.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        eps = max(eps_min, eps * eps_decay)\n",
    "        if ep % update_target_every == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        if (ep + 1) % 20 == 0:\n",
    "            print(f\"Ep {ep+1:04d} | Reward: {total_r:.1f} | Eps: {eps:.2f}\")\n",
    "\n",
    "   \n",
    "        if (ep + 1) % 100 == 0:\n",
    "            ckpt_path = f\"checkpoints/geometry_ep{ep+1}.pth\"\n",
    "            torch.save({\n",
    "                \"episode\": ep + 1,\n",
    "                \"policy_state\": policy_net.state_dict(),\n",
    "                \"target_state\": target_net.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"epsilon\": eps,\n",
    "            }, ckpt_path)\n",
    "            print(f\"Checkpoint guardado: {ckpt_path}\")\n",
    "\n",
    "    \n",
    "    torch.save({\n",
    "        \"state_dim\": state_dim,\n",
    "        \"model_state_dict\": policy_net.state_dict()\n",
    "    }, \"geometry_dash_dqn.pth\")\n",
    "\n",
    "    print(\"Modelo final guardado como geometry_dash_dqn.pth\")\n",
    "    return policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f6b49c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Estado inicial: shape=(9,), dim=9\n",
      "‚öôÔ∏è  Usando dispositivo: cpu\n",
      "üß† Cargando checkpoint desde: checkpoints/geometry_ep500.pth\n",
      "‚úÖ Checkpoint cargado correctamente (episodio 0)\n",
      "Ep 0020 | Reward: 0.0 | Eps: 0.90\n",
      "Ep 0040 | Reward: 2.0 | Eps: 0.82\n",
      "Ep 0060 | Reward: 1.0 | Eps: 0.74\n",
      "Ep 0080 | Reward: -5.0 | Eps: 0.67\n",
      "Ep 0100 | Reward: -5.0 | Eps: 0.61\n",
      "üíæ Checkpoint guardado: checkpoints/geometry_ep100.pth\n",
      "‚úÖ Modelo final guardado como geometry_dash_dqn.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=9, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dqn(episodes=100, checkpoint_path=\"checkpoints/geometry_ep500.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
